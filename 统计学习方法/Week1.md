# 统计学习及监督学习概论

## 统计学习

统计学习->统计机器学习->机器学习

## 分类

### 基本分类

1. 监督学习 输入(x,y)[]，学习映射，输出y=f(x)/P(y|x)
2. 无监督学习 输入x[]，选定最优模型，输出$z_{N+1}=\cap{g}(x_{N+1});z_{n+1}argmax\cap P{z|x_{N+1}};...$
3. 强化学习 马尔可夫决策模型；无模型/有模型->求出最优决策策略
4. 半监督 少量标注和大量未标注；利用未标注数据辅助监督学习
5. 主动学习 不懂就问，机器给出实例让教师标注

### 模型分类

1. 概率模型/非概率模型 P(y|x)和f(x);生成模型和判别模型
2. 线性模型/非线性模型
3. 参数化模型/非参数化模型

### 算法分类

1. 在线学习
2. 批量学习

### 技巧分类

1. 贝叶斯学习->贝叶斯估计
2. 核方法

## 三要素

### 模型

获取假设空间

### 策略

选择最优模型的方法

#### 损失函数/代价函数L(Y,f(X))

非负实值函数

1. 01损失
2. 平方损失
3. 绝对损失
4. 对数损失

损失越小，效果越好

#### 风险函数

损失函数关于P(X,Y)的期望

经验风险：来自训练集

### 算法

计 算 方 法

## 模型评估与选择

 训练误差与测试误差
 模型选择与过拟合

### 正则化

结构风险最小化策略的实现；一般为模型复杂度的单调递增函数。

### 交叉验证

针对数据不足情况

1. 简单交叉验证 测试不同的模型(?)
2. S折交叉验证 S划分，S-1训练1测试，重复S次进行模型选择
3. 留一交叉验证 S=N

### 泛化能力

对未知数据的预测能力。
对泛化能力分析常常通过研究泛化误差的概率上界进行。

### 生成模型

生成方法由数据学习联合分布，进而求出条件概率分布为预测的模型为生成模型

收敛更快。可用于含隐变量的学习。可以还原出联合分布

### 判别模型

判别方法由数据直接学习f(X)/P(Y|X)作为预测模型，称为判别模型。准确率高，简化学习问题。

## 监督学习的应用

### 分类问题

准确率；
二类分类器：精确率，召回率

### 标注问题

输入观测序列，输出标记/状态序列。

隐马尔可夫模型；条件随机场

### 回归问题

预测输入和输出之间的关系


